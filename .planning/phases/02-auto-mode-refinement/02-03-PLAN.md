---
phase: 02-auto-mode-refinement
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - ~/.claude/get-shit-done/bin/gsd-escalation.js
  - ~/.claude/get-shit-done/bin/gsd-tools.js
  - .planning/validation/escalation-log.jsonl
autonomous: true

must_haves:
  truths:
    - "Weighted error scoring: rejections=1.0, fixes=0.5, retries=0.25"
    - "Escalation threshold is aggressive (1-2 errors trigger escalation)"
    - "Escalation includes explanation of what went wrong"
    - "Rework is verified to have fixed the issues"
    - "User notification is summary at end only"
  artifacts:
    - path: "~/.claude/get-shit-done/bin/gsd-escalation.js"
      provides: "Error tracking and escalation module"
      exports: ["ErrorTracker", "executeWithEscalation", "ERROR_WEIGHTS"]
    - path: ".planning/validation/escalation-log.jsonl"
      provides: "Escalation event log"
  key_links:
    - from: "gsd-escalation.js"
      to: "gsd-validator.js"
      via: "require for validateTask"
      pattern: "require.*gsd-validator"
    - from: "gsd-escalation.js"
      to: "escalation-log.jsonl"
      via: "logEscalation append"
      pattern: "appendFileSync.*escalation-log"
---

<objective>
Implement weighted error scoring and automatic escalation system that tracks error severity, escalates to stronger models when threshold exceeded, and verifies that rework fixes the issues.

Purpose: Enable smart escalation based on error severity rather than simple retry counts, preferring quality over cost savings per user decision (AUTO-12).

Output: gsd-escalation.js module with ErrorTracker class, weighted scoring, and escalation logic.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-auto-mode-refinement/02-RESEARCH.md
@.planning/phases/02-auto-mode-refinement/02-01-PLAN.md
@.planning/phases/02-auto-mode-refinement/02-02-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create error tracking and escalation module</name>
  <files>~/.claude/get-shit-done/bin/gsd-escalation.js</files>
  <action>
Create gsd-escalation.js with these components per user decisions:

1. **ERROR_WEIGHTS constant** (per user decision):
   ```javascript
   const ERROR_WEIGHTS = {
     COMPLETE_REJECTION: 1.0,  // Sonnet says "redo from scratch"
     VALIDATION_FIX: 0.5,      // Partial corrections needed
     RETRY: 0.25               // Transient failure (API timeout, etc)
   };
   ```

2. **ESCALATION_THRESHOLD** (per user decision: aggressive):
   ```javascript
   const ESCALATION_THRESHOLD = 1.0; // 1-2 errors trigger escalation
   ```

3. **ErrorTracker class**:
   ```javascript
   class ErrorTracker {
     constructor(task) {
       this.task = task;
       this.errors = [];
       this.cumulativeScore = 0;
     }

     recordError(type, explanation, fix_attempted = null) {
       // Add error to array
       // Update cumulative score
       // Log escalation event
     }

     shouldEscalate() {
       return this.cumulativeScore >= ESCALATION_THRESHOLD;
     }

     getNextModel(currentModel) {
       // Escalation ladder: haiku → sonnet → opus → null
       const ladder = { haiku: 'sonnet', sonnet: 'opus', opus: null };
       return ladder[currentModel];
     }

     getEscalationSummary() {
       // Return formatted summary of errors for end-of-execution display
       // User decision: summary at end only
     }
   }
   ```

4. **executeWithEscalation(task, executeFn, validateFn)** - Main escalation wrapper:
   - Start with task.assigned_model or 'haiku'
   - Execute task
   - If model is haiku, validate with Sonnet (calls validateFn)
   - On validation failure:
     - REDO → recordError('COMPLETE_REJECTION', explanation)
     - FIX → recordError('VALIDATION_FIX', explanation)
   - Check shouldEscalate()
   - If yes, get next model and retry
   - Include explanation of what went wrong per user decision
   - Verify rework fixes issues by re-validating after fix
   - Max 3 attempts before throwing error
   - Return { result, tracker: ErrorTracker } for summary display

5. **logEscalation(entry)** - Append to .planning/validation/escalation-log.jsonl:
   - Fields: timestamp, task_id, error_type, weight, cumulative_score, from_model, to_model, explanation

6. **displayEscalationHistory(tracker)** - Format escalation summary:
   - Called at end of execution per user decision (summary at end only)
   - Returns formatted string with error count, escalation path, reasons
  </action>
  <verify>
    - File exists: ~/.claude/get-shit-done/bin/gsd-escalation.js
    - Exports: ErrorTracker, executeWithEscalation, ERROR_WEIGHTS, displayEscalationHistory
    - ErrorTracker.shouldEscalate() returns true when score >= 1.0
    - ErrorTracker.getNextModel('haiku') returns 'sonnet'
  </verify>
  <done>
    Escalation module created with weighted error scoring, ErrorTracker class, and escalation logic
  </done>
</task>

<task type="auto">
  <name>Task 2: Add escalation CLI commands to gsd-tools.js</name>
  <files>~/.claude/get-shit-done/bin/gsd-tools.js</files>
  <action>
Add escalation subcommands to gsd-tools.js by requiring gsd-escalation.js:

1. **escalation weights** - Show error weight configuration
   - Returns: ERROR_WEIGHTS object
   - Useful for understanding how errors are scored

2. **escalation threshold** - Show escalation threshold
   - Returns: { threshold: 1.0, description: "1-2 errors trigger escalation" }

3. **escalation log** - Read escalation log
   - Args: --task-id (optional filter), --limit (default 20)
   - Returns: array of escalation entries from JSONL

4. **escalation stats** - Escalation statistics
   - Calculates: total escalations, by-model breakdown, average errors before escalation
   - Returns JSON with stats

5. **escalation simulate** - Simulate error scoring
   - Args: --errors (comma-separated: "COMPLETE_REJECTION,VALIDATION_FIX")
   - Returns: { cumulative_score, should_escalate }
   - Useful for understanding when escalation triggers

Add require for gsd-escalation.js at top of gsd-tools.js:
```javascript
const escalation = require('./gsd-escalation');
```

Pattern follows existing subcommand structure.
  </action>
  <verify>
    - `node ~/.claude/get-shit-done/bin/gsd-tools.js escalation weights` returns ERROR_WEIGHTS
    - `node ~/.claude/get-shit-done/bin/gsd-tools.js escalation simulate --errors "VALIDATION_FIX,VALIDATION_FIX"` returns { cumulative_score: 1.0, should_escalate: true }
    - `node ~/.claude/get-shit-done/bin/gsd-tools.js escalation simulate --errors "RETRY"` returns { cumulative_score: 0.25, should_escalate: false }
  </verify>
  <done>
    CLI commands for escalation operations integrated into gsd-tools.js
  </done>
</task>

<task type="auto">
  <name>Task 3: Initialize escalation log and test flow</name>
  <files>.planning/validation/escalation-log.jsonl</files>
  <action>
1. Initialize escalation-log.jsonl in .planning/validation/:
   ```json
   {"_comment":"GSD escalation event log - tracks error scoring and model escalation","created":"TIMESTAMP"}
   ```

2. Test escalation simulation flow:
   - Single RETRY: score=0.25, no escalation
   - Two VALIDATION_FIX: score=1.0, triggers escalation
   - One COMPLETE_REJECTION: score=1.0, triggers escalation
   - RETRY + VALIDATION_FIX: score=0.75, no escalation
   - RETRY + VALIDATION_FIX + RETRY: score=1.0, triggers escalation

3. Verify ErrorTracker correctly tracks cumulative scores:
   ```javascript
   const tracker = new ErrorTracker({ id: 'test' });
   tracker.recordError('VALIDATION_FIX', 'missing error handling');
   tracker.recordError('VALIDATION_FIX', 'incomplete test coverage');
   console.log(tracker.shouldEscalate()); // true
   console.log(tracker.getNextModel('haiku')); // 'sonnet'
   ```

4. Test escalation summary display:
   - Create tracker with multiple errors
   - Call displayEscalationHistory(tracker)
   - Verify output format is readable and includes all error details
  </action>
  <verify>
    - File exists: .planning/validation/escalation-log.jsonl
    - escalation simulate works correctly for all test cases
    - Error tracking math is correct (sum of weights)
  </verify>
  <done>
    Escalation log initialized, weighted scoring tested, escalation simulation working
  </done>
</task>

</tasks>

<verification>
1. ErrorTracker correctly sums weighted errors
2. Threshold of 1.0 triggers escalation at 1-2 errors (depending on type)
3. Escalation ladder progresses: haiku → sonnet → opus
4. Escalation log captures events in JSONL format
5. CLI simulation correctly predicts escalation behavior
</verification>

<success_criteria>
- ERROR_WEIGHTS match user specification (1.0, 0.5, 0.25)
- ESCALATION_THRESHOLD is aggressive (1.0 per user decision)
- ErrorTracker.shouldEscalate() returns true at cumulative score >= 1.0
- executeWithEscalation() retries with stronger model on threshold breach
- displayEscalationHistory() provides summary for end-of-execution display
</success_criteria>

<output>
After completion, create `.planning/phases/02-auto-mode-refinement/02-03-SUMMARY.md`
</output>
